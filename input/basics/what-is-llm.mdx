---

---

import PromptInjection from './assets/prompt-injection.jpg';
import PromptInjection2 from './assets/prompt-injection-2.jpg';

# Понимание LLM

В этом модуле мы проведем всесторонний обзор больших языковых моделей, таких как ChatGPT. Мы изучим, как эти модели работают, какая архитектура стоит за ними, и рассмотрим процесс их обучения.
*Для Applied AI инженера знать как работает LLM - всё равно что для электрика знать как работает электричество.*

## Steps

### 1. Смотрим видео легендарного ученого и лектора по LLM (LLM: The Movie)

Вопросы, к 1 лекции:
- Что такое большие языковые модели (LLM) и как они работают?
- Как с помощбю всех текстов интернета и кучи GPU мы получаем ChatGPT?
- Какую задачу решают LLM, подобные ChatGPT, на одном шаге? Что такое токен?
- Какие существуют примеры задач, которые LLM могут выполнять лучше всего?

<iframe width="560" height="315" src="https://www.youtube.com/embed/zjkBMFhNj_g?si=Kxz5RkVUm9Wk1LJQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### E1. Более плотное кино, также без coding/math от февраля 2025 (LLM: The returning of the Jedi)

Вопросы, к 2 лекции:
- Как происходит процесс предобучения (pre-training) языковых моделей?
- Чем отличается этап предобучения от этапа тонкой настройки (fine-tuning)?
- Что такое обучение с подкреплением и как оно применимо к LLM?
- Какие методы используются для уменьшения галлюцинаций и улучшения точности ответов LLM?
- Как "умные" модели отличаются от традиционных LLM?
- Что такое "галлюцинации" и как их избежать?

<iframe width="560" height="315" src="https://www.youtube.com/embed/7xTGNNLPyMI?si=8kshyVoS22ZCY9Na" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Перенес сиквел сюда из-за хороших отзывов студентов.

## Extra Steps

### E2. Andrej Karpathy: How I use LLMs
<iframe width="560" height="315" src="https://www.youtube.com/embed/EWvNQjAaOHw?si=hqjJsvfhscJrDo3Z" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### E3. Как работает температура
- https://lena-voita.github.io/nlp_course/language_modeling.html + ctrl+F `Sampling with temperature`.
Можно поиграться на интерактивной картинке.

### E4. [The **Illustrated** GPT-2 (Visualizing Transformer Language Models)](https://jalammar.github.io/illustrated-gpt2/) *math-less*

### E5. [матан] Интуиция за механизмами

Если вы хотите глубже погрузиться в то, как работают LLM и механизмы внутри - рекомендую посмотреть [этот плейлист](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=of9V1P2DaxOyV3zE) с отличными визуализациями и объяснениями. Смотрите начиная с "Краткое объяснение больших языковых моделей".

Длительность четырех видео: 1.5 часа, но скорее всего они займут у вас больше времени.

### E6. Промпт-инъекции наглядно

<img src={PromptInjection} alt="prompt injection" width="300" />

<img src={PromptInjection2} alt="prompt injection" width="300" />

<details>
<summary>
Почему не на все workflow подействовала промпт-инъекция?
</summary>

Версии:
- промышленные модели стараются создавать устойчивыми к промпт-инъекциям
- модели больше "внимания" обращают на системный промпт, чем на пользовательский
- слишком маленькие и глупые модели могут "не обратить внимание" на инъекцию

Также существуют промышленные инструменты для борьбы с промпт-инъекциями, например их детекция и блокировка на разных этапах workflow.

</details>

## Now we know...

В данном модуле мы глубоко исследовали принципы работы крупных языковых моделей и их тренировки, включая этапы предобучения, обучения с учителем и обучения с подкреплением. Мы увидели, как эти модели становятся инструментами, способными не только генерировать текст, но и решать сложные задачи, используя различные стратегии мышления. Важно помнить, что, хотя технологии впечатляют, их использование требует внимательного подхода и критического мышления для достижения наилучших результатов.

Зная как LLM устроена под капотом, в следущем модуле мы изучим, как выглядит LLm с другой стороны - со стороны разработчика.

## Exercises

- Из каких трех этапов обычно состоит процесс обучения LLM?
- Почему на один и тот же входной текст LLM может давать разные ответы?
- Может ли LLM отвечать на вопросы о вчерашних новостях?
- Что нужно для RLHF (Reinforcement Learning from Human Feedback)?
- Почему моделям тяжело считать количество букв "а" в слове?

Сложные:
- Что такое специальные токены?
- Почему мы затрудняемся сразу после pre-training делать RL? И что нам с этим помогает?
- Каково преимущество RLHF перед SFT?
- Что будет, если мы установим температуру равной 10?

![Ask ChatGPT](https://img.shields.io/badge/Ask%20ChatGPT-8A2BE2?style=for-the-badge)

Вы можете посмотреть другие фильмы Андрея про GPT-2 и токенизатор, если хотите обладать неверотно глубоким пониманием LLM. Для дизайна AI агентов это не обязательно.